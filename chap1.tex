% Chapter 1
%\chapter{مقدمه}

\section{مقدمه}
یادگیری فدرال

\section{کارهای مرتبط}
\subsection{جابه‌جایی فدرال}
\subsection{معیارهای مشابهت}
 
\section{مدل سیستم}
\subsection{جابه‌جایی فدرال برپایه شباهت}
\subsection{تاثیرات جابه‌جایی}

در این بخش، تاثیرات مختلف جابه‌جایی مدل‌ها بر ترافیک شبکه و حریم شخصی بررسی شده است. ابتدا نشان داده می‌شود که روش‌های جابه‌جایی مدل‌ها هزینه ترافیک شبکه را نسبت به روش‌های سنتی افزایش نمی‌دهند و در برخی موارد حتی به کاهش آن کمک می‌کنند. سپس به بررسی تاثیرات این جابه‌جایی‌ها بر حریم شخصی کاربران پرداخته می‌شود که در آن خطرات مرتبط با تبادل مدل‌ها بین کاربران، با واسطه یا بدون واسطه سرور ارزیابی می‌شود.

\subsubsection{تاثیرات جابه‌جایی مدل‌ها بر ترافیک شبکه}
در این بخش نشان داده می‌شود که
جابه‌جایی مدل‌ها، هیچ هزینه اضافی در ترافیک شبکه نسبت به روش مرسوم \lr{FedAvg} به همراه ندارد. به بیان دقیق‌تر، این روش نه تنها هزینه‌ای بیشتر ایجاد نمی‌کند، بلکه در بهبود ترافیک شبکه نیز مؤثر است و می‌تواند به سادگی در شرایط مختلف اعمال شود. 


فرض می‌شود که تعداد کل کاربران با \(K\)، اندازه مدل با \(s\)، تعداد گام‌های بین هر جابه‌جایی مدل با \(h_1\) و تعداد جابه‌جایی‌ها بین هر میانگین‌گیری با \(h_2\) نشان داده شود.
در روش \lr{FedAvg}، در هر یک از گام‌های \( h_1 \times h_2 \)، ابتدا همه کاربران مدل‌های خود را به سرور ارسال می‌کنند. سپس سرور پس از انجام میانگین‌گیری، مدل‌های جدید را به کاربران بازمی‌گرداند. هزینه این فرآیند رفت و برگشت در هر گام برابر با \( 2Ks \) است.

در مقابل، روش \lr{FedSwap} به گونه‌ای عمل می‌کند که در \( h_2 - 1 \) مرحله اولیه، کاربران فقط مدل‌های خود را با یکدیگر مبادله می‌کنند و هیچ مدلی به سمت سرور ارسال نمی‌شود. این مبادله میان کاربران، هزینه‌ای معادل \( Ks \) دارد و تنها در گام نهایی، میانگین‌گیری انجام می‌شود.

در روش \lr{SimFedSwap}، در تمام مراحل جابجایی که شامل \( h_2 - 1 \) مرحله است، تمامی مدل‌ها به سرور ارسال می‌شوند. سپس سرور پس از بررسی شباهت مدل‌ها، آن‌ها را به کاربران بازمی‌گرداند. در نهایت، میانگین‌گیری در آخرین مرحله صورت می‌پذیرد. در این روش، در هر گام، رفت و برگشت کامل مدل‌ها انجام می‌شود که هزینه آن در تمامی مراحل برابر با \( 2Ks \) خواهد بود.

بنابراین، در هر چرخه \( h_1 \times h_2 \)، هزینه ارتباطات برای روش‌های مختلف به‌صورت زیر به دست می‌آید:
\begin{equation}
	\begin{array}{ll}
		FedAvg: & h_1h_2 (2Ks)
		\\ \\ \\
		FedSwap: & (h_2-1)(Ks) + (2Ks)
		\\ \\ \\
		SimFedSwap: & h_2(2Ks)
	\end{array}
\end{equation}


بر این اساس، میزان کاهش هزینه‌های ارتباطی در روش‌های \lr{FedSwap} و \lr{SimFedSwap} در مقایسه با روش \lr{FedAvg} به‌صورت زیر محاسبه می‌شود:
\begingroup
\addtolength{\jot}{0.5em}
\begin{equation}
	\begin{aligned} 
		\frac{FedAvg-FedSwap}{FedAvg}
		&= \frac{h_1h_2(2Ks)-((h_2-1)(Ks)+(2Ks))}{h_1h_2(2Ks)} \\
		&= \frac{2h_1h_2Ks-h_2Ks+Ks-2Ks}{2h_1h_2Ks} \\
		&= \frac{Ks(2h_1h_2 -h_2 +1 -2)}{2h_1h_2Ks} \\
		&= \frac{2h_1h_2 -h_2 -1}{2h_1h_2}
	\end{aligned}
\end{equation}
\endgroup

\begingroup
\addtolength{\jot}{0.5em}
\begin{equation}
	\begin{aligned} 
		\frac{FedAvg-SimFedSwap}{FedAvg}
		&= \frac{h_1h_2(2Ks)-(h_2(2Ks))}{h_1h_2(2Ks)} \\
		&= \frac{2h_1h_2Ks-2h_2Ks}{2h_1h_2Ks} \\
		&= \frac{2h_2Ks(h_1 -1)}{2h_1h_2Ks} \\
		&= \frac{h_1 -1}{h_1}
	\end{aligned}
\end{equation}
\endgroup


جهت فهم بهتر این ساختار و چگونگی تأثیر آن بر ترافیک شبکه، با در نظر گرفتن این که در این مثال پارامتر \(h_1\) مقدار 5 و پارامتر \(h_2\) مقدار 3 را دارند، به شکل
\ref{compare_swap_net_traffic} 
دقت کنید.
\begin{figure}[t]
	\centering
	\includegraphics[scale=0.3]{images/chap4/compare_swap_net_traffic.png}%
	\caption{%
		تأثیر نحوه جابه‌جایی مدل‌ها بر ترافیک شبکه.
	}
	\label{compare_swap_net_traffic}
	\centering
\end{figure}
به‌طور خاص، در شبیه‌سازی‌هایی که پارامترهای \(h_1\) برابر با 5 و \(h_2\) برابر با 3 در نظر گرفته شده‌اند، روش \lr{FedSwap} موفق به کاهش
۸۶٫۶۶
درصدی هزینه‌های شبکه شده است. همچنین، روش \lr{SimFedSwap} توانسته این هزینه‌ها را تا ۸۰ درصد کاهش دهد. 


\subsubsection{
	تاثیر جابجایی مدل‌ها بر حریم شخصی در ارتباط بین سرور و کاربران
}
در روش یادگیری فدرال سنتی، مانند
\lr{FedAvg}%
، مدل‌ها پس از آموزش محلی توسط کاربران، به سرور مرکزی ارسال می‌شوند. سرور وظیفه تجمیع این مدل‌ها را بر عهده دارد و سپس مدل به‌روزرسانی‌ شده را به کاربران بازمی‌گرداند. در این روش، تعاملات فقط بین سرور و کاربران صورت می‌گیرد و هیچ ارتباط مستقیمی بین کاربران وجود ندارد. این امر باعث می‌شود که حریم شخصی کاربران به دلیل عدم تبادل مستقیم اطلاعات با یکدیگر، تا حد زیادی حفظ شود. همچنین کاربران نیازی به اعتماد به یکدیگر ندارند و تنها باید به سرور مرکزی اعتماد کنند.

در مقابل، در روش‌هایی که مدل‌ها بین خود کاربران جابه‌جا می‌شود، چه با واسطه سرور و چه بدون واسطه آن، خطرات بیشتری برای حریم شخصی وجود دارد. زمانی که مدل‌ها مستقیماً بین کاربران مبادله می‌شود، احتمال این که یکی از کاربران بتواند از طریق تحلیل مدل دریافت ‌شده اطلاعاتی در مورد داده‌های دیگر کاربران به دست آورد، افزایش می‌یابد. حتی اگر سرور به عنوان واسطه در این جابجایی‌ها عمل کند، همچنان خطراتی وجود خواهد داشت، زیرا سرور می‌تواند نقش ناظر را داشته باشد و از جابجایی مدل‌ها بین کاربران سوء استفاده کند. بنابراین، در هر دو حالت، جابجایی مدل‌ها بین کاربران نسبت به
\lr{FedAvg}
با چالش‌های بیشتری در زمینه حفظ حریم شخصی مواجه است.

در نتیجه، در روش
\lr{FedAvg}%
، به دلیل عدم ارتباط مستقیم بین کاربران، حریم شخصی به شکل بهتری حفظ می‌شود و تنها سرور مرکزی باید ایمن باشد. اما در روش جابجایی مدل‌ها بین کاربران، خطر نشت اطلاعات بین کاربران افزایش می‌یابد و این روش به پروتکل‌های امنیتی پیچیده‌تر و اعتماد بیشتر بین کاربران نیاز دارد.


\subsubsection{
	تاثیر جابجایی مدل‌ها بر حریم شخصی با توجه به واسطه بودن سرور
}
روش حریم خصوصی تفاضلی که در
\ref{privacy_challenge}
نیز به آن اشاره شد یکی از تکنیک‌های موثر برای حفظ حریم شخصی است که با اضافه کردن نویز به داده‌ها یا مدل‌ها، مانع از افشای اطلاعات حساس فردی می‌شود. این روش تضمین می‌کند که خروجی یک الگوریتم یادگیری به اندازه کافی تصادفی است، به‌طوری‌که حضور یا عدم حضور یک نمونه داده خاص در مجموعه داده‌ها، تاثیری بر خروجی نهایی نداشته باشد.

حال اگر از این روش در جابجایی مدل‌ها بین کاربران استفاده شود، تفاوت‌هایی بین دو رویکرد با واسطه سرور و بدون واسطه سرور وجود خواهد داشت. در حالتی که سرور واسطه باشد، اعمال حریم خصوصی تفاضلی می‌تواند به کنترل و مدیریت نویز اضافه شده کمک کند و سرور می‌تواند نقش فعالی در تضمین این که مدل‌ها به درستی ناشناس‌ شده‌اند، ایفا کند. این امر باعث می‌شود که خطر نشت اطلاعات به دلیل واسطه‌گری سرور کاهش یابد. اما همچنان باید به سرور اعتماد کرد که این فرآیند را به درستی انجام دهد.

در رویکرد بدون واسطه سرور، اعمال حریم خصوصی تفاضلی چالش‌برانگیزتر است، زیرا کاربران به‌طور مستقل باید نویز لازم را به مدل‌های خود اضافه کنند و در عین حال مطمئن شوند که سطح مناسبی از حفظ حریم شخصی برقرار است. در این حالت، هرگونه خطا یا ناهماهنگی در اعمال حریم خصوصی تفاضلی ممکن است منجر به افشای اطلاعات حساس شود. همچنین، نبود یک ناظر مرکزی مانند سرور، کار را برای هماهنگی و اجرای صحیح این روش پیچیده‌تر می‌کند.

در نتیجه، در صورت استفاده از روش حریم خصوصی تفاضلی، رویکرد با واسطه سرور به دلیل نظارت و کنترل متمرکز، از لحاظ حفظ حریم شخصی مزیت بیشتری دارد. در مقابل، در رویکرد بدون واسطه سرور، چالش‌های بیشتری برای کاربران وجود دارد که می‌تواند منجر به کاهش اثربخشی حریم خصوصی تفاضلی شود.
البته باید به این نکته اشاره کرد که حفظ حریم شخصی یکی از ارکان مهم در یادگیری فدرال است و برای سنجش دقیق میزان نفوذپذیری آن، لازم است روش‌های تخصصی در این حوزه به‌صورت مجزا پیاده‌سازی و بررسی شوند.
از آن جاکه در این پژوهش، تمرکز اصلی بر بهبود دقت مدل نهایی است، ورود به جزئیات حوزه امنیت خارج از محدوده مطالب مربوط به این پژوهش می‌باشد. با این حال تلاش شده تا حریم شخصی نیز تا حد امکان مورد توجه قرار گیرد.





\subsection{نحوه جابه‌جایی}
زمانی که همه مدل‌های شبکه عصبی در سرور مرکزی قرار دارند، وظیفه سرور این است که تصمیم بگیرد کدام کاربران مدل‌های خود را با یکدیگر جابه‌جا کنند. برای انجام این کار، ابتدا باید مدل‌ها با یکدیگر مقایسه شوند تا میزان شباهت بین آن‌ها مشخص شود. سپس، بر اساس این شباهت‌ها تعیین می‌شود که کدام کاربران مدل‌های شبکه عصبی خود را با یکدیگر مبادله کنند، یا به عبارت دیگر، سرور مشخص می‌کند کدام مدل به کدام کاربر ارسال شود.

\subsubsection{جابه‌جایی حریصانه}

در روش حریصانه، از بین تمام کاربران موجود، یک کاربر به‌صورت تصادفی انتخاب می‌شود. سپس مدل شبکه عصبی این کاربر با مدل‌های تمامی کاربران دیگر مقایسه می‌شود تا میزان شباهت آن‌ها سنجیده شود. در این مرحله، کاربری که مدل شبکه عصبی او کمترین شباهت را با مدل کاربر انتخاب‌ شده دارد، به عنوان کاربر مقصد برای جابه‌جایی مدل انتخاب می‌شود. پس از این انتخاب، سرور مدل‌های این دو کاربر را با یکدیگر جابه‌جا می‌کند و در نهایت این دو کاربر را از لیست انتخاب حذف خواهد کرد.

پس از انجام این جابه‌جایی، فرایند مشابهی برای کاربران باقی‌مانده تکرار می‌شود. ابتدا یک کاربر دیگر به‌صورت تصادفی انتخاب می‌شود و دقیقا همان روند بالا برای آن تکرار خواهد شد.
شبه کد کامل این روش در الگوریتم
\ref{algo_greedy_swapping}
ارائه شده است. علاوه بر این، نمادهای مختص به این الگوریتم در جدول
\ref{tabel_GreedySwappingNotations}
و همچنین تمامی نمادهای پایه در جدول
\ref{tabel_FedAvgNotations}
توضیح داده شده‌اند.
هدف از این جداول، فراهم کردن درکی جامع از نحوه عملکرد و پیاده‌سازی الگوریتم می‌باشد.


\begin{LTR}
	\SetAlgoNlRelativeSize{-1}
	\begin{algorithm}[t]
		\begin{RTL}
			\caption{%
				جابه‌جایی حریصانه
				\lr{(Greedy Swapping)}
			}
			\label{algo_greedy_swapping}
		\end{RTL}
		
		\begin{latin}
			\SetKwFunction{GreedySwapping}{GreedySwapping}
			\SetKwProg{Fn}{Function}{:}{end}
			\Fn{\GreedySwapping{}}{
				$LRS$ = copy of $U_t$\;
				$NS$ = (length of $U_t$ // 2) * $SP$\;
				\BlankLine
				
				\For{$NS$ times}{
					$RandomIndex$ = random integer between $0$ and length of $LRS$\;
					$SCB = LRS[RandomIndex]$\;
					remove $SCB$ from $LRS$\;
					
					\BlankLine
					Initialize $LstSimilarity$ as an empty list\;
					\For{each $RC \in LRS$}{
						$Sim = \texttt{ModelSimilarity} (w^{SCB}, w^{RC})$\;
						Append $Sim$ to $LstSimilarity$\;
					}
					$MinSimilarityIndex$ = index of the minimum value in $LstSimilarity$\;
					$SCD = LRS[MinSimilarityIndex]$\;
					remove $SCD$ from $LRS$\;
					\BlankLine
					
					$\texttt{Swap}(SCB, SCD)$\;
				}
			}
		\end{latin}
	\end{algorithm}
\end{LTR}

\begin{table}[h]
	\centering
	\caption{نمادهای مختص الگوریتم جابه‌جایی حریصانه}
	\label{tabel_GreedySwappingNotations}
	\begin{tabular}{cr}
		\hline
		متغیر & توضیحات \\
		\hline
		$LRS \, (LstRemainSwap)$ & لیست باقی‌مانده جابه‌جایی \\
		$NS \, (NumSwaps)$ & تعداد جابه‌جایی‌ها \\
		$SP \, (SwapPercentage)$ & ضریب کنترلی برای تعداد جابه‌جایی‌ها \\
		$RandomIndex$ & شاخص تصادفی \\
		$SCB \, (SwapClientBase)$ & کاربر مبدا جابه‌جایی \\
		$LstSimilarity$ & لیست مشابهت \\
		$RC \, (RemainClient)$ & کاربر باقی‌مانده \\
		$Sim$ & معیار مشابهت بین دو مدل شبکه عصبی \\
		$SCD \, (SwapClientDest)$ & کاربر مقصد جابه‌جایی
	\end{tabular}
\end{table}




\subsubsection{جابه‌جایی حداقل شباهت}

در این روش، برای این که حداقل شباهت ممکن بین تمامی مدل‌های شبکه عصبی به دست آید، لازم است تمامی مدل‌ها با یکدیگر مقایسه شوند و دو مدلی که کمترین شباهت را دارند با هم جابه‌جا شوند. به عنوان مثال، اگر \( n \) مدل وجود داشته باشد، باید یک ماتریس \( n \times n \) برای بررسی میزان شباهت‌ها ایجاد شود. در این ماتریس، شباهت مدل 1 با مدل 2 برابر با شباهت مدل 2 با مدل 1 در نظر گرفته می‌شود. همچنین به دلیل این که مقایسه یک مدل با خودش بی‌معنی است، ماتریس نهایی به شکل یک ماتریس بالا مثلثی%
\LTRfootnote{Upper Triangular Matrix}
(بدون قطر اصلی) تبدیل می‌شود. به این صورت که تنها حدود نیمی از ماتریس، شامل شباهت‌های مورد نیاز برای مقایسه است. در نتیجه ماتریس مورد نظر به شکل زیر در خواهد آمد.
\begin{equation}
	\begin{bmatrix}
		\infty & a^{12} & a^{13} & \cdots & a^{1n} \\
		\infty & \infty & a^{23} & \cdots & a^{2n} \\
		\infty & \infty & \infty & \cdots & a^{3n} \\
		\vdots & \vdots & \vdots & \ddots & \vdots \\
		\infty & \infty & \infty & \cdots & \infty
	\end{bmatrix}
	\label{eq_similarity_matrix}
\end{equation}

ابتدا، تمامی شباهت‌ها بین مدل‌ها محاسبه می‌شود و سپس از ماتریس ایجاد شده، کمترین مقدار شباهت انتخاب می‌شود. شماره سطر و ستون متناظر با این مقدار نشان می‌دهد که این دو مدل باید با یکدیگر جابه‌جا شوند. پس از انجام این جابه‌جایی، تمامی مقدارهای مربوط به سطر و ستون متناظر با این دو مدل باید به بی‌نهایت تغییر داده شوند تا در مراحل بعدی مجدد انتخاب نشوند. همچنین باید دقت کرد که هر دو سطر و ستون مرتبط با این دو مدل باید به بی‌نهایت تغییر داده شوند.

برای درک بهتر، فرض کنید کمترین مقدار شباهت در سطر سوم و ستون ششم ماتریس قرار دارد. در این حالت، مدل‌های سوم و ششم باید با یکدیگر جابه‌جا شوند. پس از این جابه‌جایی، لازم است که تمامی مقادیر در سطرهای سوم و ششم و همچنین ستون‌های سوم و ششم به بی‌نهایت تغییر کنند تا این دو مدل دیگر مورد بررسی قرار نگیرند. به این ترتیب، در دور بعدی، کوچک‌ترین مقدار شباهت از ماتریس انتخاب می‌شود و چون مقادیر مربوط به مدل‌های سوم و ششم به بی‌نهایت تغییر کرده‌اند، دیگر در این مرحله حضور نخواهند داشت و انتخاب نمی‌شوند. شبه کد کامل این روش در الگوریتم
\ref{algo_min_similarity_swapping}
ارائه شده است. علاوه بر این، نمادهای مختص به این الگوریتم در جدول
\ref{tabel_MinSimilaritySwapNotations}
توضیح داده شده‌اند.


\begin{LTR}
	\SetAlgoNlRelativeSize{-1}
	\begin{algorithm}[t]
		\begin{RTL}
			\caption{%
				جابه‌جایی حداقل شباهت
				\lr{(Minimum Similarity Swapping)}
			}
			\label{algo_min_similarity_swapping}
		\end{RTL}
		
		\begin{latin}
			\SetKwFunction{MinSimilaritySwapping}{MinSimilaritySwapping}
			\SetKwProg{Fn}{Function}{:}{end}
			\Fn{\MinSimilaritySwapping{}}{
				Initialize $SimArray$\;
				$L$ = length of $U_t$\;
				\BlankLine
				
				\For{each $row$ from $0$ to $L$}{
					\For{each $col$ from $(row+1)$ to $L$}{
						$Sim = \texttt{ModelSimilarity} (w^{row}, w^{col})$\;
						Append $Sim$ to $SimArray$\;
					}
				}
				\BlankLine
				
				$NS$ = ($L$ // 2) * $SP$\;
				\For{$NS$ times}{
					$MI$ = index of minimum value in $SimArray$\;
					$row, col$ = find $row$ and $col$ number, based on $MI$\;					
					Set all values of $SimArray[row, col]$ to $\infty$\;
					\BlankLine
					
					$\texttt{Swap}(w^{row}, w^{col})$\;
				}
			}
		\end{latin}
	\end{algorithm}
\end{LTR}


\begin{table}[h]
	\centering
	\caption{نمادهای مختص الگوریتم جابه‌جایی حداقل شباهت}
	\label{tabel_MinSimilaritySwapNotations}
	\begin{tabular}{cr}
		\hline
		متغیر & توضیحات \\
		\hline
		$SimArray$ & آرایه مشابهت \\
		$L$ & طول مجموعه‌ای از کاربران در گام $t$ \\
		$MI \, (MinIndex)$ & شاخص مقدار کمینه در آرایه مشابهت \\
		$row$ & شماره سطر بر اساس دید ماتریس مشابهت \\
		$col$ & شماره ستون بر اساس دید ماتریس مشابهت
	\end{tabular}
\end{table}








\section{بررسی نتایج}
\subsection{
	مجموعه داده
	\lr{\texttt{\fontspec{Times New Roman} MNIST}}%
	\LTRfootnote{Modified National Institute of Standards and Technology}
}
اکنون نتایج مربوط به مجموعه داده
\lr{MNIST}
بررسی خواهد شد که شکل
\ref{result_mnist_mlp}
نتایج مقایسه روش
\lr{SimFedSwap}
با سایر روش‌های مرجع را با استفاده از مدل
\lr{MLP}
به تصویر می‌کشد.
\begin{figure}[t]
	\centering
	\subfigure[
	دید کلی از نتیجه
	\qquad\hspace{3mm}]{
		\label{result_mnist_mlp_mid}
		\includegraphics*[width=.441\textwidth]{images/chap5/result/mnist/acc_mid_mlp.png}
	}
	\hspace{0.8mm}
	\subfigure[
	بزرگ‌نمایی شده بخش اصلی					
	\qquad\hspace{5mm}]{
		\label{result_mnist_mlp_zoom}
		\includegraphics*[width=.441\textwidth]{images/chap5/result/mnist/acc_zoom_mlp.png}
	}
	\caption{
		مقایسه منحنی‌های دقت در مجموعه داده
		\lr{MNIST}
		با استفاده از مدل
		\lr{MLP}.
	}
	\label{result_mnist_mlp}
\end{figure}
همچنین، پارامترهای به‌کاررفته در این اجرا در جدول
\ref{tabel_parameter_mnist} 
به نمایش درآمده‌اند.
%\addtolength{\tabcolsep}{-0.5mm}
\begin{table}[t]
	\centering
	\caption{
		پارامترهای اجرا در مجموعه داده
		\lr{MNIST}
	}
	\label{tabel_parameter_mnist}
	%	\scalebox{0.985}{
		\begin{tabular}{ccccccccccccc}
			\hline
			\specialcell{مجموعه\\داده} &
			\specialcell{نحوه\\جابه‌جایی} &
			\specialcell{توزیع\\داده} &
			$K$ &
			$B$ &
			$C$ &
			$SP$ &
			$\eta$ &
			$E$ &
			$h_1$ &
			$h_2$
			\\
			\hline
			\lr{MNIST} &
			\lr{MSS} &
			نرمال &
			\lr{10} &
			\lr{32} &
			\lr{1.0} &
			\lr{1.0} &
			\lr{0.001} &
			\lr{1} &
			\lr{5} &
			\lr{3}
			\\
		\end{tabular}
		%	}
\end{table}
نکته قابل توجه این است که منحنی‌های
\lr{FedAvg} 
و
\lr{FedSwap} 
به عنوان منحنی‌های نهایی و مرجع بر روی سایر منحنی‌ها قرار گرفته‌اند. در صورتی که رنگ متفاوتی در نمودار دیده شود، این موضوع نشان‌دهنده اختلاف عملکرد روش مربوطه در آن نقطه خواهد بود. این تغییر ممکن است نشان‌دهنده عملکرد بهتر یا ضعیف‌تر در مقایسه با دیگر روش‌ها باشد و می‌تواند به عنوان مبنایی برای مقایسه و تحلیل مورد توجه قرار گیرد.




همان‌طور که در شکل
\ref{result_mnist_mlp} 
مشاهده می‌شود، روش‌های مبتنی‌بر جابه‌جایی به شکل بسیار ناچیزی از روش
\lr{FedAvg} 
نتایج مطلوب‌تری را ارائه داده‌اند. نکته قابل توجه این است که همه روش‌های مبتنی‌بر جابه‌جایی عملکردی مشابه داشته‌اند. برای بررسی دقیق‌تر این اجرا، منحنی‌های خطا در شکل
\ref{app_result_mnist_mlp}
پیوست، قابل مشاهده هستند.


در شکل
\ref{result_mnist_cnn}
همان آزمایش قبلی تکرار شده، با این تفاوت که این مرتبه از مدل شبکه عصبی
\lr{CNN}
استفاده شده است. همان‌طور که دیده می‌شود، تقریباً تمامی روش‌ها عملکرد مشابهی داشته‌اند. این نکته نشان می‌دهد که وقتی شبکه به راحتی به دقت بالایی می‌رسد، تفاوتی در نتایج بین روش‌ها دیده نمی‌شود. برای جزئیات بیشتر این اجرا، منحنی‌های خطا در شکل
\ref{app_result_mnist_cnn}
پیوست، آمده‌اند.


\begin{figure}[t]
	\centering
	\subfigure[
	دید کلی از نتیجه
	\qquad\hspace{3mm}]{
		\label{result_mnist_cnn_mid}
		\includegraphics*[width=.48\textwidth]{images/chap5/result/mnist/acc_mid_cnn.png}
	}
	\hspace{0.8mm}
	\subfigure[
	بزرگ‌نمایی شده بخش اصلی					
	\qquad\hspace{5mm}]{
		\label{result_mnist_cnn_zoom}
		\includegraphics*[width=.48\textwidth]{images/chap5/result/mnist/acc_zoom_cnn.png}
	}
	\caption{
		مقایسه منحنی‌های دقت در مجموعه داده
		\lr{MNIST}
		با استفاده از مدل
		\lr{CNN}.
	}
	\label{result_mnist_cnn}
\end{figure}





\FloatBarrier
\subsection{
	مجموعه داده
	\lr{\texttt{\fontspec{Times New Roman} CIFAR-10}}%
	\LTRfootnote{Canadian Institute For Advanced Research}
}
اکنون نتایج مربوط به مجموعه داده
\lr{CIFAR-10}
بررسی خواهد شد که شکل
\ref{result_cifar10_equal}
نتایج مقایسه روش
\lr{SimFedSwap}
با سایر روش‌های مرجع را با توزیع داده یکنواخت بین کاربران به تصویر می‌کشد.
پارامترهای استفاده شده در این آزمایش نیز در جدول
\ref{tabel_parameter_cifar10}
به نمایش درآمده‌اند.


\begin{figure}[t]
	\centering
	\subfigure[
	دید کلی از نتیجه
	\qquad\hspace{3mm}]{
		\label{result_cifar10_equal_mid}
		\includegraphics*[width=.48\textwidth]{images/chap5/result/cifar10/acc_mid_equal.png}
	}
	\hspace{0.8mm}
	\subfigure[
	بزرگ‌نمایی شده بخش اصلی					
	\qquad\hspace{5mm}]{
		\label{result_cifar10_equal_zoom}
		\includegraphics*[width=.48\textwidth]{images/chap5/result/cifar10/acc_zoom_equal.png}
	}
	\caption{
		مقایسه منحنی‌های دقت در مجموعه داده
		\lr{CIFAR-10}
		با توزیع داده یکنواخت.
	}
	\label{result_cifar10_equal}
\end{figure}


%\addtolength{\tabcolsep}{-0.5mm}
\begin{table}[t]
	\centering
	\caption{
		پارامترهای اجرا در مجموعه داده
		\lr{CIFAR-10}
	}
	\label{tabel_parameter_cifar10}
	%	\scalebox{0.985}{
		\begin{tabular}{ccccccccccccc}
			\hline
			\specialcell{مجموعه\\داده} &
			\specialcell{شبکه\\عصبی} &
			\specialcell{نحوه\\جابه‌جایی} &
			$K$ &
			$B$ &
			$C$ &
			$SP$ &
			$\eta$ &
			$E$ &
			$h_1$ &
			$h_2$
			\\
			\hline
			\lr{CIFAR-10} &
			\lr{Conv} &
			\lr{MSS} &
			\lr{10} &
			\lr{64} &
			\lr{1.0} &
			\lr{1.0} &
			\lr{0.001} &
			\lr{2} &
			\lr{3} &
			\lr{10}
			\\
		\end{tabular}
		%	}
\end{table}


همان‌طور که در شکل
\ref{result_cifar10_equal}
مشاهده می‌شود، روش‌های مبتنی‌بر جابه‌جایی نسبت به روش
\lr{FedAvg}
عملکرد متمایزی داشته‌اند. با این حال، این روش‌ها در یک سطح عملکردی نزدیک به هم قرار گرفته‌اند. به‌طور کلی، با وجود اختلافات جزئی، روش‌های مبتنی‌بر شباهت در مقایسه با روش
\lr{FedSwap}
کمی بهتر عمل کرده‌اند. برای آگاهی از جزئیات بیشتر، به منحنی‌های خطا در شکل
\ref{app_result_cifar10_equal}
پیوست، توجه نمایید.


در شکل
\ref{result_cifar10_normal}%
، آزمایش قبلی دوباره اجرا شده، اما این بار از توزیع داده نرمال استفاده شده است. مشاهده می‌شود که در این وضعیت نیز روش‌های مبتنی‌بر جابه‌جایی، عملکرد بهتری نسبت به روش
\lr{FedAvg}
داشته‌اند. البته، نتایج حاصل از روش‌های جابه‌جایی تقریباً مشابه بوده و تفاوت قابل توجهی بین آن‌ها دیده نمی‌شود. برای مشاهده جزئیات بیشتر، می‌توان به منحنی‌های خطا در شکل
\ref{app_result_cifar10_normal}
پیوست، مراجعه کرد.

\begin{figure}[t]
	\centering
	\subfigure[
	دید کلی از نتیجه
	\qquad\hspace{3mm}]{
		\label{result_cifar10_normal_base}
		\includegraphics*[width=.48\textwidth]{images/chap5/result/cifar10/acc_base_normal.png}
	}
	\hspace{0.8mm}
	\subfigure[
	بزرگ‌نمایی شده بخش اصلی					
	\qquad\hspace{5mm}]{
		\label{result_cifar10_normal_zoom}
		\includegraphics*[width=.48\textwidth]{images/chap5/result/cifar10/acc_zoom_normal.png}
	}
	\caption{
		مقایسه منحنی‌های دقت در مجموعه داده
		\lr{CIFAR-10}
		با توزیع داده نرمال.
	}
	\label{result_cifar10_normal}
\end{figure}




\FloatBarrier
\subsection{
	مجموعه داده
	\lr{\texttt{\fontspec{Times New Roman} CINIC-10}}%
	\LTRfootnote{CIFAR-10 and ImageNet Combined}
}

اکنون نتایج مربوط به مجموعه داده
\lr{CINIC-10}
بررسی خواهد شد که شکل
\ref{result_cinic10}
نتایج مقایسه روش
\lr{SimFedSwap}
با سایر روش‌های مرجع را به تصویر می‌کشد.
همچنین، پارامترهای به کار رفته در این آزمایش در جدول
\ref{tabel_parameter_cinic10}
ارائه شده‌اند.

\begin{figure}[t]
	\centering
	\subfigure[
	دید کلی از نتیجه
	\qquad\hspace{3mm}]{
		\label{result_cinic10_mid}
		\includegraphics*[width=.48\textwidth]{images/chap5/result/cinic10/acc_mid.png}
	}
	\hspace{0.8mm}
	\subfigure[
	بزرگ‌نمایی شده بخش اصلی					
	\qquad\hspace{5mm}]{
		\label{result_cinic10_zoom}
		\includegraphics*[width=.48\textwidth]{images/chap5/result/cinic10/acc_zoom.png}
	}
	\caption{
		مقایسه منحنی‌های دقت در مجموعه داده
		\lr{CINIC-10}.
	}
	\label{result_cinic10}
\end{figure}


%\addtolength{\tabcolsep}{-0.5mm}
\begin{table}[t]
	\centering
	\caption{
		پارامترهای اجرا در مجموعه داده
		\lr{CINIC-10}
	}
	\label{tabel_parameter_cinic10}
	%	\scalebox{0.985}{
		\begin{tabular}{ccccccccccccc}
			\hline
			\specialcell{مجموعه\\داده} &
			\specialcell{شبکه\\عصبی} &
			\specialcell{نحوه\\جابه‌جایی} &
			\specialcell{توزیع\\داده} &
			$K$ &
			$B$ &
			$C$ &
			$SP$ &
			$\eta$ &
			$E$ &
			$h_1$ &
			$h_2$
			\\
			\hline
			\lr{CINIC-10} &
			\lr{Conv} &
			\lr{MSS} &
			نرمال &
			\lr{30} &
			\lr{64} &
			\lr{0.5} &
			\lr{1.0} &
			\lr{0.001} &
			\lr{1} &
			\lr{2} &
			\lr{5}
			\\
		\end{tabular}
		%	}
\end{table}


در شکل
\ref{result_cinic10}
به‌وضوح می‌توان مشاهده کرد که روش‌های مبتنی‌بر جابه‌جایی در مقایسه با روش
\lr{FedAvg}%
، عملکرد متفاوتی داشته‌اند. هرچند، این روش‌ها همچنان در یک سطح عملکردی نزدیک به هم قرار دارند و تفاوت‌های عمده‌ای میان آن‌ها دیده نمی‌شود. برای بررسی دقیق‌تر، منحنی‌های خطا در شکل
\ref{app_result_cinic10}
پیوست، به تفصیل آمده‌اند.







\FloatBarrier
\subsection{
	مجموعه داده
	\lr{\texttt{\fontspec{Times New Roman} FEMNIST}}%
	\LTRfootnote{Federated Extended MNIST}
}
در این مجموعه داده، تعداد داده‌ها در هر کلاس یکسان نیست و کلاس‌های مختلف دارای تعداد متفاوتی از داده‌ها هستند. شکل
\ref{count_all_classes}%
، تعداد داده‌های هر کلاس و نحوه نام‌گذاری آن‌ها را نشان می‌دهد.


\begin{figure}[t]
	\centering
	\includegraphics[scale=0.7]{images/chap5/count_all_classes.png}%
	\caption{%
		تعداد داده‌های هر کلاس و نحوه نام‌گذاری در مجموعه داده
		\lr{FEMNIST}.
	}
	\label{count_all_classes}
	\centering
\end{figure}

همان‌طور که در شکل
\ref{count_all_classes}
مشاهده می‌شود، تعداد کلاس‌های 0 تا 9 که به ارقام 0 تا 9 اشاره دارند، به‌طور قابل‌توجهی بیشتر از سایر کلاس‌هاست و هر کدام حدود 40٬000 نمونه دارند. در بین کلاس‌های 10 تا 35 که مربوط به حروف بزرگ انگلیسی هستند، کلاس‌های \lr{S} و \lr{O} بیشترین تعداد نمونه را دارند. به نظر می‌رسد این سبک از جمع‌آوری داده به دلیل جلوگیری از اشتباه گرفتن کلاس \lr{O} با عدد صفر و کلاس \lr{S} با معادل حرف کوچک آن در کلاس‌های 36 تا 61 بوده باشد.


مجموعه داده
\lr{FEMNIST}
به‌صورت پیش‌فرض شامل 3597 کاربر است که داده‌ها میان این کاربران توزیع شده‌اند. این توزیع، نه از لحاظ تعداد تصاویر بین کاربران و نه از لحاظ پوشش‌دهی کلاس‌ها در هر کاربر، یکسان نیست. با این حال، تعداد کاربران و نحوه توزیع داده‌ها میان آن‌ها را می‌توان به دلخواه تغییر داد.



اکنون رویکردهای پایه در مجموعه داده
\lr{FEMNIST}
بررسی خواهند شد. در رویکرد اول، داده‌ها بدون توجه به کاربران اصلی و تنها بر اساس کلاس‌های آن‌ها تفکیک می‌شوند. به این صورت که تمام داده‌های مربوط به هر کلاس جمع‌آوری شده و طبق یک توزیع مشخص بین تعدادی کاربر تقسیم می‌شوند. این روش به عنوان رویکرد کلاس‌بندی یا
\lr{FEMNISTclass}
شناخته می‌شود.

در رویکرد دوم، ساختار اصلی مجموعه داده تغییر نمی‌کند و تعداد کاربران همان تعداد پیش‌فرض باقی می‌ماند. همچنین داده‌ها دقیقا به همان شیوه‌ای که به هر کاربر اختصاص داده شده‌اند، حفظ می‌شوند. این روش به نام رویکرد نویسندگان یا
\lr{FEMNISTwriter}
نام‌گذاری شده است. در ادامه نتایج مربوط به هر کدام از این رویکرد‌ها به‌صورت مجزا بررسی خواهد شد.






\subsubsection{
	مقایسه نتایج در رویکرد کلاس‌بندی
	\lr{\texttt{\fontspec{Times New Roman} (FEMNISTclass)}}
}

نتایج مقایسه روش
\lr{SimFedSwap}
با دیگر روش‌های مرجع در شکل
\ref{result_FEMNISTclass}
نمایش داده شده‌اند که این آزمایش بر روی مجموعه داده
\lr{FEMNISTclass}
انجام شده است. پارامترهای مورد استفاده در این آزمایش نیز در جدول
\ref{tabel_parameter_FEMNISTclass}
ذکر شده‌اند.


\begin{figure}[t]
	\centering
	\subfigure[
	دید کلی از نتیجه
	\qquad\hspace{3mm}]{
		\label{result_FEMNISTclass_base}
		\includegraphics*[width=.48\textwidth]{images/chap5/result/FEMNISTclass/acc_base.png}
	}
	\hspace{0.8mm}
	\subfigure[
	بزرگ‌نمایی شده بخش اصلی					
	\qquad\hspace{5mm}]{
		\label{result_FEMNISTclass_zoom}
		\includegraphics*[width=.48\textwidth]{images/chap5/result/FEMNISTclass/acc_zoom.png}
	}
	\caption{
		مقایسه منحنی‌های دقت در مجموعه داده
		\lr{FEMNISTclass}.
	}
	\label{result_FEMNISTclass}
\end{figure}


%\addtolength{\tabcolsep}{-0.5mm}
\begin{table}[t]
	\centering
	\caption{
		پارامترهای اجرا در مجموعه داده
		\lr{FEMNISTclass}
	}
	\label{tabel_parameter_FEMNISTclass}
	%	\scalebox{0.985}{
		\begin{tabular}{ccccccccccccc}
			\hline
			\specialcell{مجموعه\\داده} &
			\specialcell{شبکه\\عصبی} &
			\specialcell{نحوه\\جابه‌جایی} &
			\specialcell{توزیع\\داده} &
			$K$ &
			$B$ &
			$C$ &
			$SP$ &
			$\eta$ &
			$E$ &
			$h_1$ &
			$h_2$
			\\
			\hline
			\lr{FEMNISTclass} &
			\lr{Conv} &
			\lr{MSS} &
			یکنواخت &
			\lr{200} &
			\lr{1024} &
			\lr{1.0} &
			\lr{1.0} &
			\lr{0.001} &
			\lr{2} &
			\lr{5} &
			\lr{3}
			\\
		\end{tabular}
		%	}
\end{table}



از شکل
\ref{result_FEMNISTclass}
مشخص است که روش‌های مبتنی‌بر جابه‌جایی در مقایسه با
\lr{FedAvg}
عملکرد متفاوتی نشان می‌دهند، اما همچنان تفاوت‌های عملکردی بین آن‌ها محدود و نزدیک به هم است.
نکته قابل توجه این است که بسیاری از تغییرات در نمودارها به لحظات جابه‌جایی یا میانگین‌گیری مربوط می‌شوند.
برای جزئیات بیشتر و بررسی دقیق‌تر، می‌توان به منحنی‌های خطا که در شکل
\ref{app_result_FEMNISTclass}
پیوست آمده‌اند، مراجعه کرد.




\subsubsection{
	مقایسه نتایج در رویکرد نویسندگان
	\lr{\texttt{\fontspec{Times New Roman} (FEMNISTwriter)}}
}
نتایج مربوط به مقایسه روش
\lr{SimFedSwap}
با سایر روش‌های مرجع در شکل
\ref{result_FEMNISTwriter_one}
قابل مشاهده است. این آزمایش بر روی مجموعه داده
\lr{FEMNISTwriter}
اجرا شده و پارامترهای به‌کاررفته در آن نیز در جدول
\ref{tabel_parameter_FEMNISTwriter}
ذکر شده‌اند.


\begin{figure}[t]
	\centering
	\subfigure[
	دید کلی از نتیجه
	\qquad\hspace{3mm}]{
		\label{result_FEMNISTwriter_one_base}
		\includegraphics*[width=.48\textwidth]{images/chap5/result/FEMNISTwriter/acc_base_one.png}
	}
	\hspace{0.8mm}
	\subfigure[
	بزرگ‌نمایی شده بخش اصلی					
	\qquad\hspace{5mm}]{
		\label{result_FEMNISTwriter_one_zoom}
		\includegraphics*[width=.48\textwidth]{images/chap5/result/FEMNISTwriter/acc_zoom_one.png}
	}
	\caption{
		مقایسه منحنی‌های دقت در یک اجرا بر روی مجموعه داده
		\lr{FEMNISTwriter}.
	}
	\label{result_FEMNISTwriter_one}
\end{figure}


%\addtolength{\tabcolsep}{-0.5mm}
\begin{table}[t]
	\centering
	\caption{
		پارامترهای اجرا در مجموعه داده
		\lr{FEMNISTwriter}
	}
	\label{tabel_parameter_FEMNISTwriter}
	%	\scalebox{0.985}{
		\begin{tabular}{ccccccccccccc}
			\hline
			\specialcell{مجموعه\\داده} &
			\specialcell{شبکه\\عصبی} &
			\specialcell{نحوه\\جابه‌جایی} &
			\specialcell{توزیع\\داده} &
			$K$ &
			$B$ &
			$C$ &
			$SP$ &
			$\eta$ &
			$E$ &
			$h_1$ &
			$h_2$
			\\
			\hline
			\lr{FEMNISTwriter} &
			\lr{Conv} &
			\lr{MSS} &
			یکنواخت &
			\lr{3597} &
			\lr{64} &
			\lr{0.15} &
			\lr{1.0} &
			\lr{0.001} &
			\lr{1} &
			\lr{5} &
			\lr{3}
			\\
		\end{tabular}
		%	}
\end{table}


در شکل
\ref{result_FEMNISTwriter_one}
مشاهده می‌شود که روش‌های مبتنی‌بر جابه‌جایی نتایجی متفاوت از روش
\lr{FedAvg}
ارائه داده‌اند. اما نکته مهم، برتری قابل توجه روش‌های مبتنی‌بر شباهت نسبت به
\lr{FedSwap}
است. این اولین آزمایشی است که در آن روش‌های شباهت محور توانسته‌اند عملکرد بهتری را به‌طور معناداری ارائه کنند. برای اطلاعات بیشتر و تحلیل دقیق‌تر، می‌توان به منحنی‌های خطا در شکل
\ref{app_result_FEMNISTwriter_one}
پیوست، مراجعه کرد.



با بهبود نتایج، این پرسش پیش می‌آید که آیا این برتری در شرایط استفاده از چندین
\lr{Seed}
متفاوت، همچنان پابرجا خواهد بود. برای پاسخ به این سوال، آزمایش قبلی با پنج
\lr{Seed}
مختلف تکرار شده و میانگین نتایج در شکل
\ref{result_FEMNISTwriter_seed}
نمایش داده شده‌اند. نکته قابل توجه این است که اختلاف روش مبتنی‌بر شباهت با روش
\lr{FedSwap}%
، دیگر به وضوح قبلی دیده نمی‌شود و تنها، بهبودی حدود یک درصد در میانگین پنج اجرا مشاهده می‌شود.
\begin{figure}[t]
	\centering
	\subfigure[
	دید کلی از نتیجه
	\qquad\hspace{3mm}]{
		\label{result_FEMNISTwriter_seed_base}
		\includegraphics*[width=.48\textwidth]{images/chap5/result/FEMNISTwriter/acc_base_seed.png}
	}
	\hspace{0.8mm}
	\subfigure[
	بزرگ‌نمایی شده بخش اصلی					
	\qquad\hspace{5mm}]{
		\label{result_FEMNISTwriter_seed_zoom}
		\includegraphics*[width=.48\textwidth]{images/chap5/result/FEMNISTwriter/acc_zoom_seed.png}
	}
	\caption{
		مقایسه منحنی‌های دقت در میانگین پنج اجرا بر روی مجموعه داده
		\lr{FEMNISTwriter}.
	}
	\label{result_FEMNISTwriter_seed}
\end{figure}
همچنین باید به این نکته توجه شود که تغییر
\lr{Seed}
در نمودارهای پیشین، تفاوت چشم‌گیری در خروجی ایجاد نمی‌کردند.
برای بررسی جزئیات بیشتر، منحنی‌های خطا در شکل
\ref{app_result_FEMNISTwriter_seed}
پیوست ارائه شده‌اند.


بنابراین می‌توان نتیجه گرفت که با افزایش تعداد کاربران و داده‌های مربوط به آن‌ها، روش‌های مبتنی بر شباهت، هرچند به میزان کم، می‌توانند عملکرد بهتری نشان دهند.
باید به این نکته توجه داشت که دقت کلی که در این مجموعه داده به 50 درصد رسید، وابسته به طراحی شبکه عصبی است. با بهینه‌سازی این شبکه، می‌توان به دقت بالاتری دست یافت. با این حال، این بهینه‌سازی تأثیری بر مقایسه بین روش‌ها نخواهد داشت، زیرا همه روش‌ها به‌طور همزمان به دقت بهتری دست خواهند یافت.



\subsection{
	مقایسه جابه‌جایی حریصانه با جابه‌جایی حداقل شباهت در روش
	\lr{\texttt{\fontspec{Times New Roman} SimFedSwap}}
}

شکل
\ref{result_MSS_vs_GS_FEMNISTwriter}
عملکرد دو روش جابه‌جایی حریصانه و جابه‌جایی حداقل شباهت را در الگوریتم
\lr{SimFedSwap}
مقایسه می‌کند. این آزمایش بر روی مجموعه داده
\lr{FEMNISTwriter}
انجام شده و پارامترهای مربوط به این بررسی در جدول
\ref{tabel_parameter_FEMNISTwriter}
آورده شده است.


\begin{figure}[t]
	\centering
	\subfigure[
	دید کلی از نتیجه
	\qquad\hspace{3mm}]{
		\label{result_MSS_vs_GS_FEMNISTwriter_base}
		\includegraphics*[width=.48\textwidth]{images/chap5/result_MSS_vs_GS/FEMNISTwriter/acc_base.png}
	}
	\hspace{0.8mm}
	\subfigure[
	بزرگ‌نمایی شده بخش اصلی					
	\qquad\hspace{5mm}]{
		\label{result_MSS_vs_GS_FEMNISTwriter_zoom}
		\includegraphics*[width=.48\textwidth]{images/chap5/result_MSS_vs_GS/FEMNISTwriter/acc_zoom.png}
	}
	\caption{
		مقایسه منحنی‌های دقت بین
		\lr{MSS}
		و
		\lr{GS}%
		، در مجموعه داده
		\lr{FEMNISTwriter}.
	}
	\label{result_MSS_vs_GS_FEMNISTwriter}
\end{figure}



نتایج به دست آمده از شکل
\ref{result_MSS_vs_GS_FEMNISTwriter}
نشان می‌دهد که معیار
\lr{OSAD}
با استفاده از جابه‌جایی حریصانه عملکردی مشابه روش
\lr{FedSwap}
داشته است. اما روش‌های
\lr{CKA}
با استفاده از هسته‌های خطی و گاوسی به تدریج عملکرد خود را بهبود بخشیده و به نتایج بهتری دست یافته‌اند. برای اطلاعات دقیق‌تر، منحنی‌های خطا در شکل
\ref{app_result_MSS_vs_GS_FEMNISTwriter}
پیوست، قابل بررسی هستند.



